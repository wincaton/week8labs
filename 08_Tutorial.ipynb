{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b099af2f-8938-4aea-b766-ba56a219404e",
   "metadata": {},
   "source": [
    "UM MSBA - BGEN632\n",
    "\n",
    "# Week 8: Advanced Data Manipulation\n",
    "\n",
    "In the previous week, we covered approaches for filtering and querying data using various techniques. In this tutorial, we will go over how to perform advanced filtering and querying using `pandas` in Python. To start, let's set up our notebook.\n",
    "\n",
    "### Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379881e-9414-4290-88c8-d17beb35939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f863e581-7e94-4b69-b6c8-729a2833158b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set working directory\n",
    "os.chdir(\"/Users/obn/Documents/GitHub/UM-BGEN632/week8labs/data\")  # add your filepath\n",
    "os.getcwd()  # confirm change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f1e77-57f7-4f0a-9f49-a822af700c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "ozone_df = pd.read_table(\"ozone.data.txt\")\n",
    "ozone_df.info()  # quick inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef23212e-a9c6-4f1d-b7f2-5ad4ce86aa00",
   "metadata": {},
   "source": [
    "## Advanced Data Manipulation in Python\n",
    "Many of the operations found in pandas mimic those found in R's [tidyverse library](https://www.tidyverse.org/). For example, pandas provides close equivalents to the functions provided in dplyr (a core tidyverse package) which is designed to support data wrangling tasks:\n",
    "\n",
    "| `dplyr` | `pandas` |\n",
    "|:---:|:---:|\n",
    "| select | [filter](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.filter.html) |\n",
    "| filter | [query](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html) |\n",
    "| arrange | [sort_values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html) |\n",
    "| mutate | [assign](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.assign.html) |\n",
    "| rename | [rename](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) |\n",
    "| summarize | [agg](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.agg.html) |\n",
    "| group_by | [groupby](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html) |\n",
    "\n",
    "<br><br>\n",
    "In addition to these functions, another similarity includes using *pipes* as shortcuts. Piping provides the output of the previous line of code as input into the next line of code. Piping is useful for organizing multiple lines of code that should be run in sequence.\n",
    "\n",
    "For those familiar with R, we can use piping `%>%` to create streamlined, simple R code like so:\n",
    "\n",
    "```R\n",
    "ozone_df %>% \n",
    "    select(rad, temp, wind) %>%  # select desired columns\n",
    "    filter(wind == 6.3) %>%  # keep rows based on condition\n",
    "    head()  # display first n rows\n",
    "```\n",
    "\n",
    "In the code above, the output for each line is passed to the line below it. The advantage is the *lack of a need to assign the output to a variable*. Remember, assigning a value to a variable is one of the most fundamental aspects of programming. This reduces the complexity of code, the amount of text we type, and creates a clean appearance.\n",
    "\n",
    "The equivalent code in Python is provided in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2a9180-5f41-4f72-a094-c4c7aa721898",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ozone_df\n",
    " .filter([\"rad\", \"temp\", \"wind\"])  # select desired columns\n",
    " .query(\"wind == 6.3\")  # keep rows based on condition\n",
    " .head()  # display first n rows\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3cee3-9cd9-4b82-83d8-74c039c07a0a",
   "metadata": {},
   "source": [
    "You can see the similarities between the R code and Python code above. Note that we wrapped the entire Python code in parentheses `()` because otherwise we would need to place a backslash at the end of each line like so:\n",
    "\n",
    "```Python\n",
    "ozone_df \\\n",
    " .filter([\"rad\", \"temp\", \"wind\"]) \\\n",
    " .query(\"wind == 6.3\") \\\n",
    " .head() \n",
    "```\n",
    "\n",
    "Another difference between pandas and tidyverse: lots of (single or double) quotes. Unlike tidyverse, which attempts to use as few quotes as possible, pandas relies on the underlying Python base which forces the use of quotes here. Could the pandas programmers have changed that? Sure. Yet, it does keep things Pythonic.\n",
    "\n",
    "Let's use a different example that adds in more complexity. Here is an example with R code:\n",
    "\n",
    "```R\n",
    "ozone_data %>% \n",
    "    select(rad, temp, wind) %>%  # select desired columns\n",
    "    filter(temp %in% 60:90) %>%  # keep rows based on value in specified range\n",
    "    mutate(rad_wind = rad * wind) %>%  # create a new column based on mathematical operation applied to two other columns\n",
    "    arrange(desc(rad_wind)) %>%  # sort the data largest to smallest based on value in new column\n",
    "    head()  # display first n rows\n",
    "```\n",
    "\n",
    "Okay, now we'll convert the above example over to Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a5d01-a93f-4ea7-b638-a47943c325e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(range(60, 91))  # create a range that we will use later for selecting rows\n",
    "\n",
    "(ozone_df\n",
    " .filter([\"rad\", \"temp\", \"wind\"])  # select desired columns\n",
    " .query(\"temp in @l\")  # keep rows based on value in specified range\n",
    " .assign(rad_wind = ozone_df.rad * ozone_df.wind)  # create a new column based on mathematical operation applied to two other columns\n",
    " .sort_values(by = (\"rad_wind\"), ascending = False) # sort the data largest to smallest based on value in new column\n",
    " .head(6)  # display first n rows\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741d2762-35ac-489b-8359-6b83fcee74ae",
   "metadata": {},
   "source": [
    "A couple of important points to consider. First, the range of numbers in `query()`. At first glance, it would seem appropriate to do this:\n",
    "\n",
    "```Python\n",
    ".query(\"temp in 62:89\")\n",
    "```\n",
    "This would error out, unfortunately. The next idea might be performing the following:\n",
    "\n",
    "```Python\n",
    ".query(\"temp in list(range(60, 90))\")\n",
    "```\n",
    "\n",
    "Python will return the error! \n",
    "\n",
    "As an alternative, we create the list of values outside the query and reference it inside the query. The variable `l` contains the list of numerical values: `l = list(range(60, 90))`.\n",
    "\n",
    "Inside the `query()` function we can reference `l` by using the notation `@` like so: `.query(\"temp in @l\")`. \n",
    "\n",
    "In fact, we can reference any variable outside the query using this notation. We can also use this notation to reference a variable in `filter()`.\n",
    "\n",
    "The `in` operator evaluates the existence of some value inside a list. Unfortunately, we cannot create a list within the `query()` function using the function `range()`. As an alternative, we can explicitly state the list like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c42e83-3d46-4a39-9af6-8461141ef1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "(ozone_df\n",
    " .filter([\"rad\", \"temp\", \"wind\"])\n",
    " .query(\"temp in [62, 64, 68, 90]\")\n",
    " .assign(rad_wind = ozone_df.rad * ozone_df.wind)\n",
    " .sort_values(by = (\"rad_wind\"), ascending = False)\n",
    " .head(6)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386d3740-2532-42eb-8195-be299739913f",
   "metadata": {},
   "source": [
    "We did not include all the possible values between 62 and 90, but you get the picture. \n",
    "\n",
    "One last important consideration here. With `dplyr`, when you use `group_by()` it is in conjunction with `summarize()`. The same applies here for pandas: when you use `groupby()` you need to pair it with `agg()`.\n",
    "\n",
    "\n",
    "### Select Columns: `filter()`\n",
    "\n",
    "Using tidyverse, the function `filter()` selects rows. In pandas, the function `filter()` selects columns.\n",
    "\n",
    "Selecting columns is fairly straight forward. The syntax is:\n",
    "\n",
    "```Python\n",
    ".filter([\"rad\", \"temp\", \"wind\"])\n",
    "```\n",
    "\n",
    "*Be sure to encapsulate columns within square brackets and wrap column names with quotation marks*. In addition to listing column names, we can use regular expressions. Regex just has a way of creeping in when you least expect (or want) it. Think of it as a taste of things to come.\n",
    "\n",
    "For example, if we only want columns that end with the letter *d* the syntax is:\n",
    "\n",
    "```Python\n",
    "(ozone_df\n",
    " .filter(regex = \"d$\")\n",
    ")\n",
    "```\n",
    "\n",
    "### Select Rows: `query()`\n",
    "\n",
    "The function `query()` is similar to tidyverse's `filter()` in that it specifies specific rows based on a set of criteria. We can use the following with `filter()`:\n",
    "* <\n",
    "* \\>\n",
    "* <=\n",
    "* \\>=\n",
    "* ==\n",
    "\n",
    "We can also chain together multiple comparisons using the `&` operator for *and* and `|` operator for *or*. For example, instead of this expression:\n",
    "\n",
    "```Python\n",
    ".query(\"temp in @l\")\n",
    "```\n",
    "\n",
    "We could write:\n",
    "\n",
    "```Python\n",
    ".query(\"temp >= 60 & temp <= 90\")\n",
    "```\n",
    "\n",
    "The next set of operators are `in` and `not in`. In addition to the examples we have already covered, we can use these to compare columns against each other. For example, let's create a simple data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15d3db-da50-4868-9ec9-ca792d16c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': np.random.randint(3, size = 12),\n",
    "                   'b': np.random.randint(15, size = 12)})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf50474d-213c-4209-b6ee-b0315d97490f",
   "metadata": {},
   "source": [
    "Now, let's query it to evaluate if a value in column `a` is contained in column `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a02663-787d-45b9-9ba4-6b8f79515c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .query(\"a in b\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722e1c47-282e-4573-84bd-a58ac42116b0",
   "metadata": {},
   "source": [
    "The results show that only the values of 0 exist in column `b`.\n",
    "\n",
    "### Arrange Rows: `sort_values()`\n",
    "\n",
    "We can sort and order data based on columns in pandas using the function `sort_values()`. This allows us to sort a dataset given an ordered list of variables. The syntax is:\n",
    "\n",
    "```Python\n",
    ".sort_values(by = [\"col_1\", \"col_2\", \"col_3\", \"etc\"])\n",
    "```\n",
    "\n",
    "Note that this function sorts the data in ascending order by default. To sort the data in descending order, use `ascending = False` like so: \n",
    "\n",
    "```Python\n",
    ".sort_values(by = [\"col_1\", \"col_2\", \"col_3\", \"etc\"], ascending = False)\n",
    "```\n",
    "\n",
    "Be sure to specify which direction to sort to get desired results!\n",
    "\n",
    "If there are missing values in the data, we can place them at the top or end of the sort by using `na_position = \"first\"` for the top and `na_position = \"last\"` for the bottom.\n",
    "\n",
    "### Add New Columns: `assign()`\n",
    "\n",
    "We can create new columns of data from the existing columns in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf181ae-1ebf-48c5-bd3b-69977f666e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df\n",
    " .assign(c = df.a * df.b + 23 - 3.67,\n",
    "         d = lambda x: (x.b - x.c)*(3 + x.c))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6b655-71ad-4f29-8ef2-1167bd250bc7",
   "metadata": {},
   "source": [
    "The notation is slightly different from the previous example. Note, we included the function `lambda x:` and reference each column using `x.b` or `x.c` instead of `df.b` or `df.c`. This is because the newly created column `c` does not actually exist in the data frame. The changes are saved in memory, but not the DataFrame `df`.\n",
    "\n",
    "To preserve the simpler notation without using `lambda` we would have to save an intermediary data frame and then execute the second `assign()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155d68a8-dcb8-4f44-ac35-b51a0878fe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = (df\n",
    "        .assign(c = df.a * df.b + 23 - 3.67)\n",
    "       )\n",
    "\n",
    "(df_2\n",
    " .assign(d = (df_2.b - df_2.c)*(3 + df_2.c))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d678125-d599-4c0a-8c78-20c23b6e0b86",
   "metadata": {},
   "source": [
    "This defeats the purpose, though, of using the streamlined notation of pandas and piping. Yet, it is not wrong. It is very much still Pythonic.\n",
    "\n",
    "### Rename Columns: `rename()`\n",
    "\n",
    "To rename a column, we can use the function `rename()`. \n",
    "\n",
    "Each column changed is given in a pair with the original column name first, the new name second, separated by a colon `original_name:new_name`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a4c91-ba99-40b8-9f22-e324ba160722",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3 = (df_2\n",
    "        .rename(columns={'a':'azure', \n",
    "                         'b':'blue',\n",
    "                         'c':'cyan'})\n",
    "       )\n",
    "\n",
    "df_3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316432d4-839b-450d-901a-15c2e1dcd021",
   "metadata": {},
   "source": [
    "As an alternative, if we do not want to create a new DataFrame, we can perform the operation in place like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7346cdbd-7f0c-47b0-939d-2e9816deccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_2\n",
    " .rename({'a':'azure',\n",
    "          'b':'blue',\n",
    "          'c':'cyan'},\n",
    "         axis = 1,\n",
    "         inplace = True)\n",
    ")\n",
    "\n",
    "df_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d39d9d-9ad0-473e-aef7-e79efcb6a97e",
   "metadata": {},
   "source": [
    "### Summaries of Data: `agg()`\n",
    "\n",
    "The function `agg()` is an alias for *aggregate* `aggregate()`. The alias is preferred, though you can use both interchangeably. Sometimes we need to collapse many rows together by taking some kind of summary statistic. The `agg()` function allows for mutating data towards this goal. \n",
    "\n",
    "Below is a simple example of mutating each column using `sum` and `min`. Recall, `df_2` contains three columns of data, with columns `azure`, `blue`, and `cyan`.\n",
    "\n",
    "We can compute the sum for each column as well as the minimum value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c6480d-fcf3-4b6d-8bca-dcb5b46f3bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_2\n",
    " .agg([\"sum\", \"min\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa7f1e-0968-4c8d-b304-51d46dc45cfc",
   "metadata": {},
   "source": [
    "What if we are not interested in the minimum for column `b`? What if, instead, we want the maximum value? And, what if we do not want the maximum value for column `a`? In addition, we still want the sum for both columns. Oh, and one more request. What if we want the sum, maximum, and minimum for column `c`?\n",
    "\n",
    "pandas has us covered. We can use `agg()` to do this, giving it the variables containing values to collapse and the functions used to aggregate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c93d25-de6c-4daf-a2b9-3170adacb6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_2\n",
    ".agg({\n",
    "    'azure':['sum', 'min'],\n",
    "    'blue':['sum', 'max'],\n",
    "    'cyan':['sum', 'min', 'max']\n",
    "    })\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ced6afe-ca72-4c74-86a6-f3758c155819",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "That wraps up this week's tutorial! As always, review the content in this tutorial as needed. Proceed to the lab assignments once you feel ready to complete them.\n",
    "\n",
    "Next week we will go over the implementation of statistical approaches in Python. See you then!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc00b1b-6746-4138-a1c8-e84af9e15eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
